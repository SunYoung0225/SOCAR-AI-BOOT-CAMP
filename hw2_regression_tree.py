# -*- coding: utf-8 -*-
"""HW2_Regression Tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W1wa-4CAn-FId1e22O8TcQP2XDCB7sWz
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

"""Regression Tree with Tada ETA data"""

tada_eta = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Data/tada_eta.xlsx')
print(tada_eta.columns)
tada_eta.head()

tada_eta['distance'] = ((tada_eta['pickup_lat']-tada_eta['driver_lat'])**2 + (tada_eta['pickup_lng']-tada_eta['driver_lng'])**2)*100000
tada_eta = tada_eta.drop(['id', 'created_at_kst', 'driver_id', 'pickup_lng', 'pickup_lat', 'driver_lng','driver_lat','pickup_gu'],1)
tada_eta.head()

tada_eta.shape

train = tada_eta[:12000]
test = tada_eta[12000:]

x_train = np.asarray(train.drop('ATA',1))
y_train = np.asarray(train['ATA'])
x_test = np.asarray(test.drop('ATA',1))
y_test = np.asarray(test['ATA'])
eta_features = [x for i,x in enumerate(tada_eta.columns) if i!=0]

eta_features

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn import ensemble

"""1. Gradient Boosting"""

reg = ensemble.GradientBoostingRegressor(
      n_estimators = 100,
      max_depth = 3,
      min_samples_leaf = 5,
      learning_rate = 0.05,
      loss = 'ls')
reg.fit(x_train, y_train)

mse = mean_squared_error(y_test, reg.predict(x_test))
print("The mean squared error (MSE) on test set: {:.4f}".format(mse))
print("The initial error of API ETA on test set: {:.4f}".format(mean_squared_error(y_test, x_test[:,0]) ))

mae = mean_absolute_error(y_test, reg.predict(x_test))
print("The mean absolute error (MAE) on test set: {:.4f}".format(mae))
print("The initial error of API ETA on test set: {:.4f}".format(mean_absolute_error(y_test, x_test[:,0]) ))

"""1-1. Gradient Boosting: Gradient Boosting Parameter 변경"""

reg = ensemble.GradientBoostingRegressor(
      n_estimators = 200,
      max_depth = 4,
      min_samples_leaf = 5,
      learning_rate = 0.05,
      max_features = 'sqrt',
      loss = 'ls',
      random_state = 0)
reg.fit(x_train, y_train)

mse = mean_squared_error(y_test, reg.predict(x_test))
print("The mean squared error (MSE) on test set: {:.4f}".format(mse))
print("The initial error of API ETA on test set: {:.4f}".format(mean_squared_error(y_test, x_test[:,0]) ))

mae = mean_absolute_error(y_test, reg.predict(x_test))
print("The mean absolute error (MAE) on test set: {:.4f}".format(mae))
print("The initial error of API ETA on test set: {:.4f}".format(mean_absolute_error(y_test, x_test[:,0]) ))

"""2. RandomForestRegressor 사용"""

reg = ensemble.RandomForestRegressor(
      n_estimators=200,  
      min_samples_leaf=1,
      max_depth=7,
      max_features='sqrt',
      criterion='mse',
      random_state=0,
      max_samples=0.07,
      ccp_alpha=0.01)
reg.fit(x_train, y_train)

mse = mean_squared_error(y_test, reg.predict(x_test))
print("The mean squared error (MSE) on test set: {:.4f}".format(mse))
print("The initial error of API ETA on test set: {:.4f}".format(mean_squared_error(y_test, x_test[:,0]) ))

mae = mean_absolute_error(y_test, reg.predict(x_test))
print("The mean absolute error (MAE) on test set: {:.4f}".format(mae))
print("The initial error of API ETA on test set: {:.4f}".format(mean_absolute_error(y_test, x_test[:,0]) ))