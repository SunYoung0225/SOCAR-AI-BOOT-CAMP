{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Lab 2-1. Logistic Regression.ipynb","provenance":[{"file_id":"1lXlaIhXVpduJvPiTpem5RgnwXOFrmcAd","timestamp":1632746778537}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"08Y0sxvtzmwJ"},"source":["# Lab 2-1. Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"ToxF0Q2MyVkN"},"source":["*   Regression: input data $x$를 output data $y$로 매핑하는 모델 $f$를 찾는것.\n","\n","*   Logistic Regression: 모델 $f$가 linear model의 output을 logistc function을 이용해서 0~1사이의 확률값을 예측함, 즉 $$f(\\textbf{x})=\\sigma(\\textbf{w}^T\\textbf{x}+b)=\\dfrac{1}{1+e^{-(\\textbf{w}^T\\textbf{x}+b)}}$$\n","\n","*   Loss function\n","$$\\text{Loss}(\\textbf{w})=-\\dfrac{1}{N}\\sum y\\text{log}(f(\\textbf{x}))+(1-y)\\text{log}(1-f(\\textbf{x})) $$   \n","\n","*    Gradient Descent\n","$$\\textbf{w}=\\textbf{w}-\\alpha \\dfrac{\\partial}{\\partial\\textbf{w}}\\text{Loss}(\\textbf{w})$$"]},{"cell_type":"markdown","metadata":{"id":"WvYZyVhs98ES"},"source":["#### Import torch"]},{"cell_type":"code","metadata":{"id":"YBp9D4gr90CB"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ni6o1ZL1-DZ4"},"source":["### Logistic Regression with Toy Training Data"]},{"cell_type":"code","metadata":{"id":"0IZoKVr3-D24"},"source":["x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n","y_data = [[0], [0], [0], [1], [1], [1]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeLgb82n-JAQ"},"source":["x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeopVNkB-IzA"},"source":["print(x_train.shape)\n","print(y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gd0KM7lV-YyL"},"source":["#### Compute the Hypothesis\n","$$f(\\textbf{x})=\\sigma(\\textbf{w}^T\\textbf{x}+b)=\\dfrac{1}{1+e^{-(\\textbf{w}^T\\textbf{x}+b)}}$$\n"]},{"cell_type":"code","metadata":{"id":"ifdpuDHp-2V2"},"source":["print('e^1 equals: ', torch.exp(torch.FloatTensor([1])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToO9Lga2-6Td"},"source":["W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBYR28sX_JC5"},"source":["hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CRg6qm9Q_JC5"},"source":["print(hypothesis)\n","print(hypothesis.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tXK0Hh6o_JC7"},"source":["`torch.sigmoid()` 함수를 쓸 수도 있음\n"]},{"cell_type":"code","metadata":{"id":"LoIUrE3i_JC8"},"source":["print('1/(1+e^{-1}) equals: ', torch.sigmoid(torch.FloatTensor([1])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoAVAEWQ_JC8"},"source":["hypothesis = torch.sigmoid(x_train.matmul(W) + b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTrUC-kM_JC8"},"source":["print(hypothesis)\n","print(hypothesis.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uBhMIs11_JC9"},"source":["#### Computing the Loss Function (Low-level)"]},{"cell_type":"markdown","metadata":{"id":"hKtKKh3n_JC9"},"source":["$$\\text{Loss}(\\textbf{w})=-\\dfrac{1}{N}\\sum y\\text{log}(f(\\textbf{x}))+(1-y)\\text{log}(1-f(\\textbf{x})) $$   "]},{"cell_type":"markdown","metadata":{"id":"0FvP_PXg_JC9"},"source":[" `hypothesis` and `y_train` 사이의 차이를 측정하고 싶음."]},{"cell_type":"code","metadata":{"id":"daXF82d1_JC9"},"source":["print(hypothesis)\n","print(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7r_BO9ZM_JC-"},"source":["하나의 데이터에 대해서 다음과 같이 계산 가능"]},{"cell_type":"code","metadata":{"id":"xNwzPcpI_JC-"},"source":["-(y_train[0] * torch.log(hypothesis[0]) + \n","  (1 - y_train[0]) * torch.log(1 - hypothesis[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVijn88b_JC_"},"source":["전체 데이터에 대해서는 다음과 같이 간단하게 계산 가능"]},{"cell_type":"code","metadata":{"id":"fUMktKKh_JC_"},"source":["losses = -(y_train * torch.log(hypothesis) + \n","           (1 - y_train) * torch.log(1 - hypothesis))\n","print(losses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6ddLPwB_JC_"},"source":["`.mean()` 을 사용하여 평균을 취함"]},{"cell_type":"code","metadata":{"id":"VpbOMfR-_JC_"},"source":["cost = losses.mean()\n","print(cost)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkMGAmgP_JDA"},"source":["#### Computing the Cost Function with `F.binary_cross_entropy`"]},{"cell_type":"markdown","metadata":{"id":"FM5AVk6D_JDA"},"source":["실제로는 binary classification은 자주 쓰이기 때문에 pytorch에 `F.binary_cross_entropy` 라는 함수가 구현돼있음\n","\n","(지난번 실습의 `torch.nn.MSELoss`처럼)"]},{"cell_type":"code","metadata":{"id":"km1tKeBS_JDA"},"source":["F.binary_cross_entropy(hypothesis, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6lkEwRky_JDA"},"source":["#### Training with Low-level Binary Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"SmGpKdon_JDA"},"source":["x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n","y_data = [[0], [0], [0], [1], [1], [1]]\n","x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nq-9JTuw_JDB"},"source":["# 모델 초기화\n","W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = -(y_train * torch.log(hypothesis) + \n","             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IdgFkWxY_JDB"},"source":["#### Training with `F.binary_cross_entropy`"]},{"cell_type":"code","metadata":{"id":"tGDpj5xS_JDB"},"source":["# 모델 초기화\n","W = torch.zeros((2, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 1000\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ptwVT_adBwcD"},"source":["## Logistic Regression with Real Data"]},{"cell_type":"markdown","metadata":{"id":"xGn6i4npzmwP"},"source":["### Load File from Google Drive"]},{"cell_type":"code","metadata":{"id":"9HF3DXVMP66k"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoZswxPe2qFw"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"THzp4Jbj2_WJ"},"source":["diabetes = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/diabetes.csv')\n","print(diabetes.columns)\n","diabetes.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuXP-WfSlWn"},"source":["type(diabetes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kBQn8iS3ILG"},"source":["print(\"dimension of diabetes data: {}\".format(diabetes.shape))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhbQXxdWDvAf"},"source":["### Split and prepare the dataset"]},{"cell_type":"code","metadata":{"id":"7R_psvxgCMmw"},"source":["train = diabetes[:650]\n","test = diabetes[650:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC5Y6XJ4Cy1r"},"source":["print(train.groupby('Outcome').size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sxxOmGS5C9WJ"},"source":["imbalanced dataset임을 확인 가능"]},{"cell_type":"code","metadata":{"id":"-dI4nxZjCXDn"},"source":["x_train = np.asarray(train.drop('Outcome',1))\n","y_train = np.asarray(train['Outcome'])\n","x_test = np.asarray(test.drop('Outcome',1))\n","y_test = np.asarray(test['Outcome'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKsVsvj-CuIt"},"source":["input을 normalize 해준다."]},{"cell_type":"code","metadata":{"id":"to0XDQVsDBsR"},"source":["means = np.mean(x_train, axis=0)\n","stds = np.std(x_train, axis=0)\n","x_train = (x_train - means)/stds\n","x_test = (x_test - means)/stds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KCnmDIO2Ew1g"},"source":["x_train = torch.FloatTensor(x_train)\n","y_train = torch.FloatTensor(y_train).unsqueeze(-1)\n","x_test = torch.FloatTensor(x_test)\n","y_test = torch.FloatTensor(y_test).unsqueeze(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ozuh4Z3VEUAI"},"source":["### Training with F.binary_cross_entropy"]},{"cell_type":"code","metadata":{"id":"MYkE08usDNRL"},"source":["# 모델 초기화\n","W = torch.zeros((8, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 f(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 10번마다 로그 출력\n","    if epoch % 10 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3Ji-PfWGWgY"},"source":["### Test Accuracy"]},{"cell_type":"code","metadata":{"id":"l4qojW57U_DT"},"source":["W, b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCMVKeM2GhXB"},"source":["hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n","prediction = hypothesis >= torch.FloatTensor([0.5])\n","correct_prediction = prediction.float() == y_test\n","accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","print('The model has an accuracy of {:2.2f}% for the test set.'.format(accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"il5iL00VGanK"},"source":["## (Optional) Balancing the training set"]},{"cell_type":"code","metadata":{"id":"t_AcaEkeEb2V"},"source":["x_train = np.asarray(train.drop('Outcome',1))\n","y_train = np.asarray(train['Outcome'])\n","x_test = np.asarray(test.drop('Outcome',1))\n","y_test = np.asarray(test['Outcome'])\n","means = np.mean(x_train, axis=0)\n","stds = np.std(x_train, axis=0)\n","x_train = (x_train - means)/stds\n","x_test = (x_test - means)/stds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZy3OEY0HN6y"},"source":["x_train_pos = x_train[y_train == 0]\n","x_train_neg = x_train[y_train == 1]\n","y_train_pos = y_train[y_train == 0]\n","y_train_neg = y_train[y_train == 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1eZ9tJCIDzW"},"source":["x_train_pos.shape, x_train_neg.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhGla92yIXfX"},"source":["ids = np.arange(len(x_train_neg))\n","choices = np.random.choice(ids, len(x_train_pos))\n","x_train_neg = x_train_neg[choices]\n","y_train_neg = y_train_neg[choices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtFyJOWZJQlL"},"source":["x_train = np.concatenate([x_train_pos, x_train_neg], axis=0)\n","y_train = np.concatenate([y_train_pos, y_train_neg], axis=0)\n","\n","order = np.arange(len(x_train))\n","np.random.shuffle(order)\n","x_train = x_train[order]\n","y_train = y_train[order]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7trLOiUfKCKv"},"source":["x_train = torch.FloatTensor(x_train)\n","y_train = torch.FloatTensor(y_train).unsqueeze(-1)\n","x_test = torch.FloatTensor(x_test)\n","y_test = torch.FloatTensor(y_test).unsqueeze(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vS80UNMPKCKx"},"source":["### Training with F.binary_cross_entropy"]},{"cell_type":"code","metadata":{"id":"1P5miFc0KCKx"},"source":["# 모델 초기화\n","W = torch.zeros((8, 1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)\n","# optimizer 설정\n","optimizer = optim.SGD([W, b], lr=1)\n","\n","nb_epochs = 100\n","for epoch in range(nb_epochs + 1):\n","\n","    # Cost 계산\n","    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n","    cost = F.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 f(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 10번마다 로그 출력\n","    if epoch % 10 == 0:\n","        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","            epoch, nb_epochs, cost.item()\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTComXX4KCKy"},"source":["### Test Accuracy"]},{"cell_type":"code","metadata":{"id":"qHADwpx3KCKy"},"source":["hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n","prediction = hypothesis >= torch.FloatTensor([0.5])\n","correct_prediction = prediction.float() == y_test\n","accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aECJDSnAWys5"},"source":[""],"execution_count":null,"outputs":[]}]}