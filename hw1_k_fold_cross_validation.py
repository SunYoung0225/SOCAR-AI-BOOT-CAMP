# -*- coding: utf-8 -*-
"""HW1_k-fold cross validation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PXdYq36G_IRSG5sRZZRbEz2tvtuC70FK
"""

import torch
import torch.nn as nn
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""Gradient Descent로 Linear Regression (K-fold cross validation)

1) 기존 Dataset 활용
"""

file = open('/content/drive/MyDrive/Colab Notebooks/Data/regression_data.txt','r')
text = file.readlines()
file.close()

x_data = []
y_data = []

for s in text:
  data = s.split()
  x_data.append(float(data[0]))
  y_data.append(float(data[1]))

x_data = np.asarray(x_data, dtype=np.float32)
y_data = np.asarray(y_data, dtype=np.float32)

if len(x_data.shape)==1 and len(y_data.shape)==1:
  x_data = np.expand_dims(x_data, axis=-1)
  y_data = np.expand_dims(y_data, axis=-1)
print(x_data.shape, y_data.shape)

input_size = 1
output_size = 1
num_epochs = 100
learning_rate = 0.1
K = 5
n_over_k = int(len(x_data)/K)

val_losses = []

for k in range(K):
  model = nn.Linear(input_size, output_size)
  criterion = nn.MSELoss()
  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
  x_train = np.delete(x_data, slice(k*n_over_k,(k+1)*n_over_k), axis=0)
  y_train = np.delete(y_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0)

  x_valid = x_data[k*n_over_k:(k+1)*n_over_k, :]
  y_valid = y_data[k*n_over_k:(k+1)*n_over_k, :]

  for epoch in range(num_epochs):
    inputs = torch.from_numpy(x_train)
    targets = torch.from_numpy(y_train)

    outputs = model(inputs)
    loss = criterion(outputs, targets)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch+1) % 20 == 0:
      print('Epoch [{}/{}], Loss: {:,.4f}'.format(epoch+1, num_epochs, loss.item()))

  inputs = torch.from_numpy(x_valid)
  targets = torch.from_numpy(y_valid)
  outputs = model(inputs)
  loss = criterion(outputs, targets)
  print(k+1, "-th round validation error:",loss.item())
  val_losses.append(loss.item())

val_losses = np.asarray(val_losses)
print("Final validation error: ", val_losses.mean())

"""2) Dataset size 1/10로 축소"""

file = open('/content/drive/MyDrive/Colab Notebooks/Data/regression_data.txt','r')
text = file.readlines()
file.close()

x_data = []
y_data = []

for idx, s in enumerate(text):
  if idx%10==0:
    data = s.split()
    x_data.append(float(data[0]))     
    y_data.append(float(data[1]))

x_data = np.asarray(x_data, dtype=np.float32)
y_data = np.asarray(y_data, dtype=np.float32)

print(x_data.shape, y_data.shape)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.figure(1)
plt.plot(x_data, y_data, 'ro')

plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.title('My data')

plt.show()

if len(x_data.shape)==1 and len(y_data.shape)==1:
  x_data = np.expand_dims(x_data, axis=-1)
  y_data = np.expand_dims(y_data, axis=-1)
print(x_data.shape, y_data.shape)
print(len(x_data))

input_size = 1
output_size = 1
num_epochs = 100
learning_rate = 0.1
K = 5 
n_over_k = int(len(x_data)/K)

val_losses = []

for k in range(K):
  model = nn.Linear(input_size, output_size)
  criterion = nn.MSELoss()
  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
  x_train = np.delete(x_data, slice(k*n_over_k,(k+1)*n_over_k), axis=0)
  y_train = np.delete(y_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0)

  x_valid = x_data[k*n_over_k:(k+1)*n_over_k, :]
  y_valid = y_data[k*n_over_k:(k+1)*n_over_k, :]

  for epoch in range(num_epochs):
    inputs = torch.from_numpy(x_train)
    targets = torch.from_numpy(y_train)

    outputs = model(inputs)
    loss = criterion(outputs, targets)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch+1) % 20 == 0:
      print('Epoch [{}/{}], Loss: {:,.4f}'.format(epoch+1, num_epochs, loss.item()))

  inputs = torch.from_numpy(x_valid)
  targets = torch.from_numpy(y_valid)
  outputs = model(inputs)
  loss = criterion(outputs, targets)
  print(k+1, "-th round validation error:",loss.item())
  val_losses.append(loss.item())

val_losses = np.asarray(val_losses)
print("Final validation error: ", val_losses.mean())